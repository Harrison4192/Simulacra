<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Harrison Tietze" />


<title>Simulation</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="faded.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Harrison's website</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About Me</a>
</li>
<li>
  <a href="simulations.html">Sims</a>
</li>
<li>
  <a href="ML.html">ML</a>
</li>
<li>
  <a href="GLM.html">GLM</a>
</li>
<li>
  <a href="certificates.html">certificates</a>
</li>
<li>
  <a href="topology.html">Baire Space</a>
</li>
<li>
  <a href="KDE.html">KDE</a>
</li>
<li>
  <a href="https://docs.google.com/document/d/e/2PACX-1vTnpiuuxd0-ia3SMAk1SGusAyLyvwPN-wsl_dQCIC6Nglj0WgyTne0nYS1JISZZI6H-ym631b9B0kr0/pub">Novella</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Simulation</h1>
<h4 class="author"><em>Harrison Tietze</em></h4>

</div>

<div id="TOC">
<ul>
<li><a href="#methods-of-generating-random-variables"><span class="toc-section-number">1</span> Methods of Generating Random Variables</a><ul>
<li><a href="#inverse-transform-method"><span class="toc-section-number">1.1</span> Inverse Transform Method</a></li>
<li><a href="#understanding-the-inverse-transform-method"><span class="toc-section-number">1.2</span> Understanding the Inverse Transform Method</a></li>
<li><a href="#acceptance-rejection-method"><span class="toc-section-number">1.3</span> Acceptance-Rejection Method</a></li>
<li><a href="#convolutions"><span class="toc-section-number">1.4</span> Convolutions</a></li>
<li><a href="#a-mixture-of-gammas"><span class="toc-section-number">1.5</span> A Mixture of Gammas</a></li>
</ul></li>
<li><a href="#monte-carlo-integration"><span class="toc-section-number">2</span> Monte-Carlo Integration</a><ul>
<li><a href="#simple-monte-carlo-integration"><span class="toc-section-number">2.1</span> Simple Monte Carlo Integration</a></li>
<li><a href="#estimating-standard-error"><span class="toc-section-number">2.2</span> Estimating Standard Error</a></li>
<li><a href="#general-monte-carlo-integration"><span class="toc-section-number">2.3</span> General Monte-Carlo Integration</a></li>
<li><a href="#importance-sampling"><span class="toc-section-number">2.4</span> Importance Sampling</a></li>
</ul></li>
<li><a href="#numerical-algorithms"><span class="toc-section-number">3</span> Numerical Algorithms</a><ul>
<li><a href="#em-algorithm-faking-data-with-rick-and-morty"><span class="toc-section-number">3.1</span> EM algorithm: Faking data with Rick and Morty</a></li>
</ul></li>
<li><a href="#markov-chain-monte-carlo"><span class="toc-section-number">4</span> Markov Chain Monte Carlo</a><ul>
<li><a href="#markov-chain-theory"><span class="toc-section-number">4.1</span> Markov Chain theory</a></li>
<li><a href="#simulating-a-random-walk"><span class="toc-section-number">4.2</span> Simulating a Random Walk</a></li>
<li><a href="#random-walk-sampler"><span class="toc-section-number">4.3</span> Random Walk Sampler</a></li>
<li><a href="#metropolis-hastings"><span class="toc-section-number">4.4</span> Metropolis Hastings</a></li>
<li><a href="#comparison-with-accept-reject"><span class="toc-section-number">4.5</span> Comparison with Accept-Reject</a></li>
<li><a href="#multi-stage-gibbs-sampler"><span class="toc-section-number">4.6</span> Multi-stage Gibb’s sampler</a></li>
</ul></li>
</ul>
</div>

<div id="methods-of-generating-random-variables" class="section level1">
<h1><span class="header-section-number">1</span> Methods of Generating Random Variables</h1>
<div id="inverse-transform-method" class="section level2">
<h2><span class="header-section-number">1.1</span> Inverse Transform Method</h2>
<p>Let’s simulate a random sample from a distribution with density <span class="math inline">\(f(x) = \frac{3}{32}x^5 \ \ \  0&lt;x&lt;2\)</span>. We find the distribution to be <span class="math inline">\(F_X(x) = \frac{x^6}{64}\)</span> and its inverse <span class="math inline">\(x= F^{-1}_X(u) = 2u^{\frac{1}{6}}\)</span> where <span class="math inline">\(U \sim \text{Uniform}[0,1]\)</span> by the probability integral transform. We can now sample values of x:</p>
<pre class="r"><code>n &lt;- 1000
u &lt;- runif(n)
x &lt;- 2*u^(1/6)
hist(x, probability = TRUE, main = expression(f(x)==textstyle(frac(3,32))*x^5))
y &lt;- seq(0, 2, .01)
lines(y, 3/32 * y^5)</code></pre>
<p><img src="simulations_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</div>
<div id="understanding-the-inverse-transform-method" class="section level2">
<h2><span class="header-section-number">1.2</span> Understanding the Inverse Transform Method</h2>
<p>How did we get this uniform random variable? There is a method to the madness.</p>
<p>Let’s take a look at our CDF:</p>
<p><img src="simulations_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>Geometrically, we have a smooth mapping that is contracting the the interval <span class="math inline">\([0,2]\)</span> to the interval <span class="math inline">\([0,1]\)</span>. However, this is not being done evenly. Let’s bin the x-axis into intervals of width <span class="math inline">\(.25\)</span> and compute the direct image of each bin.</p>
<table>
<caption>Note infinitesimals truncated to 0</caption>
<thead>
<tr class="header">
<th align="left">bin</th>
<th align="left">image</th>
<th align="right">img_length</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">[0 , 0.25]</td>
<td align="left">[0 , 0]</td>
<td align="right">0.000</td>
</tr>
<tr class="even">
<td align="left">[0.25 , 0.5]</td>
<td align="left">[0 , 0]</td>
<td align="right">0.000</td>
</tr>
<tr class="odd">
<td align="left">[0.5 , 0.75]</td>
<td align="left">[0 , 0.003]</td>
<td align="right">0.003</td>
</tr>
<tr class="even">
<td align="left">[0.75 , 1]</td>
<td align="left">[0.003 , 0.016]</td>
<td align="right">0.013</td>
</tr>
<tr class="odd">
<td align="left">[1 , 1.25]</td>
<td align="left">[0.016 , 0.06]</td>
<td align="right">0.044</td>
</tr>
<tr class="even">
<td align="left">[1.25 , 1.5]</td>
<td align="left">[0.06 , 0.178]</td>
<td align="right">0.118</td>
</tr>
<tr class="odd">
<td align="left">[1.5 , 1.75]</td>
<td align="left">[0.178 , 0.449]</td>
<td align="right">0.271</td>
</tr>
<tr class="even">
<td align="left">[1.75 , 2]</td>
<td align="left">[0.449 , 1]</td>
<td align="right">0.551</td>
</tr>
</tbody>
</table>
<p>We partition the domain into bins of equal length, which under the image of the CDF, paritions the interval <span class="math inline">\([0,1]\)</span> into bins of <em>very</em> unequal length. If we then sample uniformly from the interval <span class="math inline">\([0,1]\)</span> and return each point to its original bin (i.e take the inverse), we will end up with our original distribution</p>
<p><img src="simulations_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>The image length is just the proportion of points sampled uniformly from [0,1] whose inverse falls into the specified bin.</p>
</div>
<div id="acceptance-rejection-method" class="section level2">
<h2><span class="header-section-number">1.3</span> Acceptance-Rejection Method</h2>
<p>Suppose we are told that a coin is flipped 50 times, 10 of which land heads. We want to simulate a sample of possibles values for the bias of the coin. We can model our belief about the bias as a beta distribution with parameters <code>a = 10</code> and <code>b = 40</code> with density <span class="math display">\[f(x) = \frac{49!}{9!39!}x^9(1-x)^{39}\]</span> <img src="simulations_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>We will use the uniform distribution as our <code>g(x)</code> since it has the same domain and is easy to sample from. Now we solve for the threshold parameter <code>c</code> which satisfies: <span class="math display">\[ \forall x \in [0,1]: \hspace{2mm}  \frac{f(x)}{g(x)} = \frac{49!}{9!39!}x^9(1-x)^{39} &lt; c\]</span>. To solve for <code>c</code>, our graph of the density reveals we should choose the mode of the distribution for our choice of <code>x</code>. which has a convenient formula: <span class="math display">\[mode = \frac{(a-1)}{(a+b-2)}\]</span></p>
<p>The mode of the beta distribution is 0.1875 and we calculate that c = 7.159. It follows that a random <code>x</code> from <code>g(x)</code> is accepted if <span class="math display">\[\frac{f(x)}{cg(x)} = \frac{\frac{49!}{9!39!}x^9(1-x)^{39}}{7.159} &gt; u\]</span></p>
<p>for some random uniform <code>u</code>.</p>
<pre class="r"><code>n &lt;- 1000  #target sample size
k &lt;- 0     #counter for accepted
j &lt;- 0     #iterations
y &lt;- numeric(n)
acceptance_ratio &lt;- function(x){beta_density(x)/my_c}

while(k &lt; n){
  acceptance_threshold &lt;- runif(1)
  j &lt;- j + 1
  x &lt;- runif(1)    #random variate from g
  if(acceptance_ratio(x) &gt; acceptance_threshold){
    #accept x
    k &lt;- k + 1
    y[k] &lt;-  x
  }
}</code></pre>
<p>In this simulation, j = 7177 iterations were required to generate a sample of n = 1000 variates, compared to the expected <span class="math inline">\(cn =\)</span> 7159 iterations. Comparing the empirical and theoretical deciles confirms that our sample fits the beta distribution.</p>
<table>
<caption>Pariwise comparison of empirical and theorectical quantile</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">10%</th>
<th align="right">20%</th>
<th align="right">30%</th>
<th align="right">40%</th>
<th align="right">50%</th>
<th align="right">60%</th>
<th align="right">70%</th>
<th align="right">80%</th>
<th align="right">90%</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Qsim</td>
<td align="right">0.1315288</td>
<td align="right">0.1525328</td>
<td align="right">0.1681874</td>
<td align="right">0.1816580</td>
<td align="right">0.1967094</td>
<td align="right">0.2097532</td>
<td align="right">0.2256079</td>
<td align="right">0.2427806</td>
<td align="right">0.2769144</td>
</tr>
<tr class="even">
<td>Q</td>
<td align="right">0.1308707</td>
<td align="right">0.1515751</td>
<td align="right">0.1675891</td>
<td align="right">0.1819719</td>
<td align="right">0.1959798</td>
<td align="right">0.2105138</td>
<td align="right">0.2266215</td>
<td align="right">0.2461659</td>
<td align="right">0.2744112</td>
</tr>
</tbody>
</table>
</div>
<div id="convolutions" class="section level2">
<h2><span class="header-section-number">1.4</span> Convolutions</h2>
<p>Let <span class="math inline">\(X_1 \dots X_n\)</span> be an i.i.d list of random variables such that <span class="math inline">\(X_j \sim X\)</span>. The distribution of their sum <span class="math inline">\(S = X_1 + \dots + X_n\)</span> is called the n-fold convolution of <span class="math inline">\(X\)</span> and has distribution <span class="math inline">\(F^{*(n)}_X\)</span>. For exapmle, the chi-squared distribution with degree of freedom <span class="math inline">\(\nu\)</span> is the <span class="math inline">\(\nu\)</span>-fold convolution of squared standard normals. Let’s use this fact to simulate a random sample of size <span class="math inline">\(n\)</span> from a <span class="math inline">\(\chi^2_{\nu}\)</span> distribution.</p>
<pre class="r"><code>library(tidyverse)
n &lt;- 1000
nu &lt;- 6
X &lt;- matrix(rnorm(n*nu), n, nu)^2
y &lt;- rowSums(X)

comp &lt;- data.frame(
theoretical = c(nu, 2*nu),
empirical = c(mean(y), mean(y^2) - (mean(y))^2),
row.names = c(&quot;mean&quot;, &quot;variance&quot;)
)

knitr::kable(comp)</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">theoretical</th>
<th align="right">empirical</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>mean</td>
<td align="right">6</td>
<td align="right">6.25575</td>
</tr>
<tr class="even">
<td>variance</td>
<td align="right">12</td>
<td align="right">12.54616</td>
</tr>
</tbody>
</table>
<p>We have accurately generated a chi-squared random sample.</p>
</div>
<div id="a-mixture-of-gammas" class="section level2">
<h2><span class="header-section-number">1.5</span> A Mixture of Gammas</h2>
<p>A discrete mixture of random variables has a distribution <span class="math display">\[F_X = \sum_{j=1}^n\theta_j F_{X_j}\]</span> where our weights <span class="math inline">\(\theta_j\)</span> sum to 1 and <span class="math inline">\(X_1 \dots X_n\)</span> is any sequence of random variables.</p>
<p>Here I will investigate the behavior of a specific mixture of gamma random variables given by <span class="math display">\[X_j \sim \text{Gamma}(r,\  \lambda_j = \frac{1}{j})\]</span> <span class="math display">\[\theta_j = \frac{2j}{n(n+1)}\]</span> <span class="math display">\[1\leq j \leq n\]</span>. Our mixed random variable is <span class="math inline">\(Y_n\)</span> with distribution <span class="math display">\[F_{Y_n} = \sum_{j=1}^n\theta_j F_{X_j}\]</span></p>
<p>I will simulate from mixtures of different sizes. Notice that in our mixture, the contribution of variables appearing later in the sequence is much higher than that of the previous ones. I hyopthesize that as <span class="math inline">\(n\)</span> increases, <span class="math inline">\(F_{Y_n} \rightarrow F_{X_n}\)</span>.</p>
<pre class="r"><code>library(tidyverse)

N &lt;- 1000 # sample size
n &lt;- 50
r &lt;- 3
gamma_mixture &lt;- function(n = 50, r = 3, N = 1000){
  # n is the number of variables we are mixing
  # N is the sample size we a generating 
  index &lt;- 1:n
  weights &lt;- index/((n*(n+1))/2)
  index_sample &lt;- sample(index, size = N, replace = TRUE, prob = weights)
  lambda &lt;- 1/index_sample
  mixture_sample &lt;- rgamma(N, shape = r, rate = lambda)
  mixture_sample
}

sizes &lt;- c(50, 200, 1000)

sizes %&gt;%
  map(function(x) gamma_mixture(n = x)) -&gt;
  mixture_list

sizes %&gt;%
  map(function(x) rgamma(N, shape = r, rate = 1/x)) -&gt; 
  gamma_list

df &lt;- tibble(
  data = c(mixture_list, gamma_list),
  n_size = rep(sizes, times = 2),
  distribution = factor(rep(c(&quot;mixture&quot;, &quot;gamma&quot;), each = 3), levels = c(&quot;mixture&quot;, &quot;gamma&quot;))
)

library(magrittr)
library(scales)
df %&lt;&gt;% unnest()

ggplot(data = df, aes(x = data)) +
  geom_density(position = &quot;stack&quot;, aes(color = distribution)) +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 3)) +
  facet_grid(. ~n_size, scales = &quot;free&quot;,  labeller = label_bquote(cols = n == .(n_size)))</code></pre>
<p><img src="simulations_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>The graphs supports our hypothesis that the similarity between the distributions of <span class="math inline">\(Y_n\)</span> and <span class="math inline">\(X_n\)</span> gets stronger as <span class="math inline">\(n\)</span> increases. You can see the sharp peak of the mixture distribution rapidly flattens out to match the gamma distribution. Note the variance of a gamma random variable <span class="math inline">\(X_n\)</span> with rate parameter <span class="math inline">\(\frac{1}{n}\)</span> and shape parameter <span class="math inline">\(r\)</span> is <span class="math display">\[ Var[X_n] = n^2r\]</span></p>
<p>so the variance increases exponentially with our choice of <span class="math inline">\(n\)</span>, flattening out the graph. In contrast, our gamma mixture takes contributions from all <span class="math inline">\(X_{1\leq j\leq n}\)</span> so it will have less variance and thus a sharper peak.</p>
<p>See:<br />
Rizzo: <a href="https://www.amazon.com/Statistical-Computing-Chapman-Hall-CRC-ebook/dp/B008MNH050/ref=sr_1_1?s=digital-text&amp;ie=UTF8&amp;qid=1506823720&amp;sr=1-1&amp;keywords=Statistical+Computing+With+R">Statistical Computing With R</a> (2007) Chapter 3: <em>Methods of Generating Random Variables</em></p>
</div>
</div>
<div id="monte-carlo-integration" class="section level1">
<h1><span class="header-section-number">2</span> Monte-Carlo Integration</h1>
<div id="simple-monte-carlo-integration" class="section level2">
<h2><span class="header-section-number">2.1</span> Simple Monte Carlo Integration</h2>
<p>We can use random number generation to estimate the integral of a function that would be difficult to solve analytically. In this case the quantity we want to estimate is really the value of an integral <span class="math inline">\(\theta = \int_{\chi}g(x)dx\)</span>. The connection between generic integrals and random variables is given by the definition of expectation of a transformed random variable. Recall that if <span class="math inline">\(X\)</span> is a random variable with density <span class="math inline">\(f(x)\)</span>, then the mathematical expectation of the transformed random variable <span class="math inline">\(g(X)\)</span> is <span class="math display">\[ \mathbb{E}_f[g(X)] = \int_{\chi}g(x)f(x)dx\]</span> where <span class="math inline">\(\chi\)</span> is the support of the density <span class="math inline">\(f\)</span>. A simple case occurs when integrating a function <span class="math inline">\(g(x)\)</span> over <span class="math inline">\([0,1]\)</span> because we can choose <span class="math inline">\(X \sim \text{Uniform}[0,1]\)</span>. <span class="math display">\[\theta = E[g(X)] = \int_0^1g(x)(1)dx = \int_0^1g(x)dx\]</span> We can then generate a random sample of uniforms <span class="math inline">\(X_1 \dots X_m\)</span> to get the monte-carlo estimate of <span class="math inline">\(\theta\)</span> using the sample mean: <span class="math display">\[\widehat{\theta}_{MC} = \widehat{\mathbb{E}_f[g(X)]}  = \frac{1}{m}\sum_{i=1}^mg(X_i)\]</span> Since <span class="math inline">\(X_1 \dots X_n\)</span> is an i.id sample, by the law of large numbers, the sample mean converges to the true expected value. <span class="math display">\[P\bigg(\lim_{m\rightarrow \infty}\left| \frac{1}{m}\sum_{i=1}^mg(X_i) - E[g(X)]\right|&lt;\epsilon \bigg) = 1\]</span> So we can expect that our estimate will approximate <span class="math inline">\(\theta\)</span> given a large enough sample. Let’s use this to estimate <span class="math display">\[\theta = \int_0^1 e^{-x}dx\]</span> and compare the estimate with the exact value.</p>
<pre class="r"><code>m &lt;- 10000
x &lt;- runif(m)
theta.hat &lt;- round(mean(exp(-x)),6)
soln &lt;- round(1-exp(-1),6)
st_err &lt;- format((1/m)*(sum(exp(-x)-theta.hat)^2)^(1/2), digits = 3)</code></pre>
<p>The estimate is <span class="math inline">\(\widehat{\theta}=\)</span> 0.631785 and <span class="math inline">\(\theta = 1 -e^{-1}\)</span> = 0.632121.</p>
</div>
<div id="estimating-standard-error" class="section level2">
<h2><span class="header-section-number">2.2</span> Estimating Standard Error</h2>
<p>We can quantify the accuracy of our estimate. Note that in statistical parlance <span class="math inline">\(\theta\)</span> is a parameter we want to estimate, and our estimator is a sample statistic <span class="math display">\[\widehat{\theta}_m = T(g(X_1), \dots g(X_m))\]</span> The population distribution of our sample statistic is called the sampling distribution. We want to find the standard deviaton of the sampling distribution called the standard error, denoted <span class="math inline">\(SE(\widehat{\theta}_m)\)</span>. Since our estimator is a sample mean from the distribution of <span class="math inline">\(g(X)\)</span>, we can estimate the standard error with <span class="math display">\[SE(\widehat{\theta}_m) = \frac{\widehat{\sigma}}{\sqrt{m}} = \frac{1}{m}\left\{\sum_{i=1}^m|g(x_i)-\overline{g(x)}]^2\right\}^{\frac{1}{2}}\]</span></p>
<p>Using this formula we calculate <span class="math inline">\(SE(\widehat{\theta}_{10^5})\)</span> = 4.61e-07 for the previous example.</p>
</div>
<div id="general-monte-carlo-integration" class="section level2">
<h2><span class="header-section-number">2.3</span> General Monte-Carlo Integration</h2>
<p>We need not limit ourselves to uniform random variables for our monte-carlo estimator. Suppose we want to estimate the quantity <span class="math inline">\(\theta = \int_{\chi}g(x)dx\)</span>. We can look for a random variable <span class="math inline">\(X\)</span> with pdf <span class="math inline">\(f\)</span> that is supported on <span class="math inline">\(\chi\)</span> and easy to sample from. Then we define the transformation <span class="math inline">\(h(X) = \frac{g(X)}{f(X)}\)</span>. Taking the expectation gives us<span class="math display">\[
\mathbb{E}_f[h(X)] = \int_{\chi}\frac{g(x)f(x)}{f(x)}dx = \int_{\chi}g(x)dx\]</span> We can get a monte-carlo estimate of <span class="math inline">\(\theta\)</span> using a sample of random variables <span class="math inline">\(X_1, \dots, X_m\)</span> generated from <span class="math inline">\(f\)</span>, tranforming them by <span class="math inline">\(h\)</span>, and tking the mean: <span class="math display">\[\widehat{\theta}_{MC} = \widehat{\mathbb{E}_f[h(X)]}  = \frac{1}{m}\sum_{i=1}^m\frac{g(X_i)}{f(X_i)}\]</span> Note that the example in (2.1) is special case where <span class="math inline">\(f(X_i) = 1\)</span> because we are using uniform random variables. In this example we will consider a function defined on an infinite domain, so we cannot choose any uniform pdf for our <span class="math inline">\(f\)</span>. Consider <span class="math display">\[\int_0^{\infty}\sin(x^2)e^{-x^2}dx\]</span> If we choose <span class="math inline">\(X \sim \exp(\lambda = 1)\)</span> then <span class="math inline">\(f(x) = e^{-x}\)</span> on <span class="math inline">\(x\geq 0\)</span> and <span class="math display">\[h(x) = \frac{\sin(x^2)e^{-x^2}}{e^{-x}} = \sin(x^2)e^{-x^2 + x}\]</span></p>
<pre class="r"><code>m &lt;- 10^5
sample &lt;- rexp(m, rate = 1)
h &lt;- function(x){
  sin(x^2)*exp(-x^2 + x)
}
estimate &lt;- sum(h(sample))/m</code></pre>
<p>Our Monte Carlo estimate <span class="math inline">\(\widehat{\theta}_{MC}\)</span> = 0.2853661 approximates the true value determined by Mathematica:</p>
<p><span class="math display">\[\pmb{\text{}}\\
\pmb{\text{Integrate}\left[\text{Sin}[x{}^{\wedge}2]*e^{-x^2}, \{x, 0 , \text{Infinity}\}\right]} = \frac{\sqrt{\pi } \ \text{Sin}\left[\frac{\pi }{8}\right]}{2\ 2^{1/4}} = 0.285185\]</span></p>
<p>See:<br />
Chihara, Hesterberg: <a href="https://www.amazon.com/Mathematical-Statistics-Resampling-Laura-Chihara-ebook/dp/B00971HDJO/ref=sr_1_1?s=digital-text&amp;ie=UTF8&amp;qid=1506823864&amp;sr=1-1&amp;keywords=Mathematical+Statistics+with+Resampling+and+R">Mathematical Statistics with Resampling and R</a> (2012) Chapter 11.6: <em>Monte Carlo Integration</em></p>
</div>
<div id="importance-sampling" class="section level2">
<h2><span class="header-section-number">2.4</span> Importance Sampling</h2>
<p>Given a density <span class="math inline">\(g\)</span> that is strictly positive on the supported domain of <span class="math inline">\(h\times f\)</span> , we can write <span class="math display">\[\mathbb{E}_f[h(X)] = \int_{\chi}h(x)\frac{f(x)}{g(x)}g(x)dx = \mathbb{E}_g\left[\frac{h(X)f(X)}{g(X)}\right]\]</span></p>
<p>Instead of sampling from a pdf <span class="math inline">\(f\)</span> we will can sample from a pdf <span class="math inline">\(g\)</span>. This <em>importance sampling fundamental identity</em> justifies the use of the estimator <span class="math display">\[\widehat{\mathbb{E}_f[h(X)]} = \frac{1}{m}\sum_{j=1}^m\frac{h(X_j)f(X_j)}{g(X_j)}\]</span> based on a sample generated from <span class="math inline">\(g\)</span>.</p>
</div>
</div>
<div id="numerical-algorithms" class="section level1">
<h1><span class="header-section-number">3</span> Numerical Algorithms</h1>
<div id="em-algorithm-faking-data-with-rick-and-morty" class="section level2">
<h2><span class="header-section-number">3.1</span> EM algorithm: Faking data with Rick and Morty</h2>
<p>Rick and Morty have just returned from an off-world adventure on alien exoplanet DW7449 where they were retreiving slime samples from Type III Lazy Slug, a possible candidate for a new flavor of Sechuan Sticky Sauce. Two important flavor variables they need to measure are the slime’s schleeb and its glubis which are known to be normally distributed. While taking measurements in Rick’s workshop, Morty slipped on a slime patch crashing into the samples, corrupting the data before they could finish recording the glubis. Fortunately, Rick had already predicted that a typical Morty-related disaster would occur, and had preprogrammed an EM algorithm to rescue the lost data. Let’s investigate what he did.</p>
<hr />
<pre class="r"><code>library(ggthemes)
library(MASS)

set.seed(3)
n &lt;- 100     #sample size
d &lt;- 2       #dimension
mu &lt;- c(1,14) #vector of means
SIGMA &lt;- matrix(c(12,3,3,6), ncol = 2, byrow = TRUE)

slime_data &lt;- data.frame(mvrnorm(n, mu, Sigma = SIGMA))

names(slime_data) = c(&quot;schleeb&quot;, &quot;glubis&quot;)

lost_data &lt;- sample(1:n, size = n/2)

slime_data[lost_data, 2] &lt;- 0 #Set the lost data values to 0


slime_plot &lt;- ggplot(slime_data, aes(schleeb, glubis)) + 
  geom_point(color = &quot;yellow&quot;) + 
  theme_solarized(light = FALSE) + 
  theme(text = element_text(size=20, color = &quot;green&quot;)) +
  stat_smooth(method = &quot;lm&quot;, color = &quot;red&quot;, se = FALSE) + 
  coord_cartesian(ylim = c(-1,20))</code></pre>
<p>This first step in the EM algorithm is create an artificially complete data set by arbitrarily setting the missing glubis values to 0. We call this dataset <span class="math inline">\(slime^{(0)}\)</span> it is plotted below. We don’t expect the regression line to be accurate.</p>
<pre class="r"><code>slime_plot</code></pre>
<p><img src="simulations_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>We know the slime data comes from a bivariate normal distribution with parameters <span class="math inline">\(\theta = (\mu_1, \mu_2, \sigma_1, \sigma_2, \rho)\)</span>. To get maximum likelihod estimates for <span class="math inline">\(\mu_2, \sigma_2\)</span>, and <span class="math inline">\(\rho\)</span> we need to properly fill in the missing data for the glubis.</p>
<p>To get one interation of the EM algorithm we can use maximum likelihood estimators to produce an estimate for <span class="math inline">\(\widehat{\theta}^{(0)} = (\mu_1^{(0)}, \mu_2^{(0)}, \sigma_1^{(0)}, \sigma_2^{(0)}, \rho^{(0)})\)</span> This is the M(“Maximization Step”)</p>
<pre class="r"><code>#construct a function that computes MLE&#39;s
theta_hat_estimator &lt;- function(schleeb = slime_data$schleeb, glubis = slime_data$glubis){
mu_1 &lt;- mean(schleeb)
mu_2 &lt;- mean(glubis)
sigma_1 &lt;- sd(schleeb)
sigma_2 &lt;- sd(glubis)
rho &lt;- cor(schleeb,glubis)
return(c(mu_1, mu_2, sigma_1, sigma_2, rho))
}</code></pre>
<p>We can now impute the missing values using the formula for conditional expectation of a bivariate normal variable where <span class="math inline">\(\theta = \widehat{\theta}^{(0)}\)</span>. This is the E“Expectation” step : <span class="math display">\[\mathbb{E}[x_{2i}|\widehat{\theta}^{(0)}] = \mu_2^{(0)} + \rho^{(0)}\frac{\sigma_2^{(0)}}{\sigma_1^{(0)}}(x_{1i} - \mu_1^{(0)}) \]</span></p>
<pre class="r"><code>#construct a function to update the slime data from slime_j -&gt; slime_j+1
impute_glubis &lt;- function(x_1, mu_1, mu_2, sigma_1, sigma_2, rho){
  mu_2 + rho*(sigma_2/sigma_1) * (x_1 - mu_1)
}</code></pre>
<p>The E and M steps are repeated giving a new dataset <span class="math inline">\(slime^{(j)}\)</span> at the <span class="math inline">\(j^{th}\)</span> stage and updating the parameter estimate <span class="math inline">\(\widehat{\theta}^{(j)}\)</span> until reaching some convergence threshold <span class="math inline">\(||\widehat{\theta}^{(j+1)} - \widehat{\theta}^{(j)}|| &lt; \epsilon\)</span>.</p>
<pre class="r"><code>#Run the EM algorithm
epsilon &lt;- .000005 # convergence threshold

theta_hat_0 &lt;- rep(0,5)  #initialize temp variable
theta_hat_1 &lt;- theta_hat_estimator(slime_data$schleeb, slime_data$glubis)
var_path &lt;- c(0,theta_hat_1)
step = 1

condition &lt;- function(){
  #convergence condition
  sqrt(sum((theta_hat_1 - theta_hat_0)^2)) &gt; epsilon
}

while(condition()) {
  #EM algorithm
 
    slime_data[lost_data, 2] &lt;- impute_glubis(slime_data[lost_data, 1], theta_hat_1[1], theta_hat_1[2], theta_hat_1[3], theta_hat_1[4], theta_hat_1[5])
  
  theta_hat_0 = theta_hat_1
  
  theta_hat_1 = theta_hat_estimator(slime_data$schleeb, slime_data$glubis)
  
  var_path = rbind(var_path, c(step, theta_hat_1))
  
  step = step + 1
}

knitr::kable(var_path, booktabs = F, align = c(&quot;c&quot;), 
             col.names =  c(&quot;step&quot;, &quot;$\\mu_1$&quot;, &quot;$\\mu_2$&quot;, &quot;$\\sigma_1$&quot;, &quot;$\\sigma_2$&quot;, &quot;$\\rho$&quot;)
             )</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="center">step</th>
<th align="center"><span class="math inline">\(\mu_1\)</span></th>
<th align="center"><span class="math inline">\(\mu_2\)</span></th>
<th align="center"><span class="math inline">\(\sigma_1\)</span></th>
<th align="center"><span class="math inline">\(\sigma_2\)</span></th>
<th align="center"><span class="math inline">\(\rho\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>var_path</td>
<td align="center">0</td>
<td align="center">0.9787029</td>
<td align="center">6.987215</td>
<td align="center">3.081482</td>
<td align="center">7.259808</td>
<td align="center">0.1191515</td>
</tr>
<tr class="even">
<td></td>
<td align="center">1</td>
<td align="center">0.9787029</td>
<td align="center">10.440005</td>
<td align="center">3.081482</td>
<td align="center">4.038984</td>
<td align="center">0.2198468</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">2</td>
<td align="center">0.9787029</td>
<td align="center">12.165318</td>
<td align="center">3.081482</td>
<td align="center">2.649032</td>
<td align="center">0.2766403</td>
</tr>
<tr class="even">
<td></td>
<td align="center">3</td>
<td align="center">0.9787029</td>
<td align="center">13.035294</td>
<td align="center">3.081482</td>
<td align="center">2.121314</td>
<td align="center">0.2766010</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">4</td>
<td align="center">0.9787029</td>
<td align="center">13.477175</td>
<td align="center">3.081482</td>
<td align="center">1.944324</td>
<td align="center">0.2495371</td>
</tr>
<tr class="even">
<td></td>
<td align="center">5</td>
<td align="center">0.9787029</td>
<td align="center">13.702908</td>
<td align="center">3.081482</td>
<td align="center">1.887004</td>
<td align="center">0.2238040</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">6</td>
<td align="center">0.9787029</td>
<td align="center">13.818741</td>
<td align="center">3.081482</td>
<td align="center">1.867507</td>
<td align="center">0.2065273</td>
</tr>
<tr class="even">
<td></td>
<td align="center">7</td>
<td align="center">0.9787029</td>
<td align="center">13.878386</td>
<td align="center">3.081482</td>
<td align="center">1.860207</td>
<td align="center">0.1962670</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">8</td>
<td align="center">0.9787029</td>
<td align="center">13.909180</td>
<td align="center">3.081482</td>
<td align="center">1.857164</td>
<td align="center">0.1904945</td>
</tr>
<tr class="even">
<td></td>
<td align="center">9</td>
<td align="center">0.9787029</td>
<td align="center">13.925111</td>
<td align="center">3.081482</td>
<td align="center">1.855776</td>
<td align="center">0.1873364</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">10</td>
<td align="center">0.9787029</td>
<td align="center">13.933366</td>
<td align="center">3.081482</td>
<td align="center">1.855101</td>
<td align="center">0.1856364</td>
</tr>
<tr class="even">
<td></td>
<td align="center">11</td>
<td align="center">0.9787029</td>
<td align="center">13.937648</td>
<td align="center">3.081482</td>
<td align="center">1.854762</td>
<td align="center">0.1847306</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">12</td>
<td align="center">0.9787029</td>
<td align="center">13.939871</td>
<td align="center">3.081482</td>
<td align="center">1.854587</td>
<td align="center">0.1842511</td>
</tr>
<tr class="even">
<td></td>
<td align="center">13</td>
<td align="center">0.9787029</td>
<td align="center">13.941026</td>
<td align="center">3.081482</td>
<td align="center">1.854497</td>
<td align="center">0.1839985</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">14</td>
<td align="center">0.9787029</td>
<td align="center">13.941626</td>
<td align="center">3.081482</td>
<td align="center">1.854449</td>
<td align="center">0.1838658</td>
</tr>
<tr class="even">
<td></td>
<td align="center">15</td>
<td align="center">0.9787029</td>
<td align="center">13.941939</td>
<td align="center">3.081482</td>
<td align="center">1.854425</td>
<td align="center">0.1837963</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">16</td>
<td align="center">0.9787029</td>
<td align="center">13.942101</td>
<td align="center">3.081482</td>
<td align="center">1.854412</td>
<td align="center">0.1837600</td>
</tr>
<tr class="even">
<td></td>
<td align="center">17</td>
<td align="center">0.9787029</td>
<td align="center">13.942186</td>
<td align="center">3.081482</td>
<td align="center">1.854405</td>
<td align="center">0.1837410</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">18</td>
<td align="center">0.9787029</td>
<td align="center">13.942229</td>
<td align="center">3.081482</td>
<td align="center">1.854402</td>
<td align="center">0.1837310</td>
</tr>
<tr class="even">
<td></td>
<td align="center">19</td>
<td align="center">0.9787029</td>
<td align="center">13.942252</td>
<td align="center">3.081482</td>
<td align="center">1.854400</td>
<td align="center">0.1837259</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">20</td>
<td align="center">0.9787029</td>
<td align="center">13.942264</td>
<td align="center">3.081482</td>
<td align="center">1.854399</td>
<td align="center">0.1837232</td>
</tr>
<tr class="even">
<td></td>
<td align="center">21</td>
<td align="center">0.9787029</td>
<td align="center">13.942270</td>
<td align="center">3.081482</td>
<td align="center">1.854398</td>
<td align="center">0.1837218</td>
</tr>
<tr class="odd">
<td></td>
<td align="center">22</td>
<td align="center">0.9787029</td>
<td align="center">13.942274</td>
<td align="center">3.081482</td>
<td align="center">1.854398</td>
<td align="center">0.1837210</td>
</tr>
</tbody>
</table>
<p>The last line in our table corresponds to the final estimates of our parameters.</p>
<pre class="r"><code>slime_plot %+% slime_data</code></pre>
<p><img src="simulations_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>This is a plot of Rick’s reconstructed data: <span class="math inline">\(slime^{(22)}\)</span>. Notice how the imputed data points lie along the regression line- since they were computed using conditional expectation, this is to by design.</p>
<p>See:<br />
Efron, Hastie: <a href="https://www.amazon.com/Computer-Age-Statistical-Inference-Mathematical-ebook/dp/B01L27MR64/ref=sr_1_fkmr1_1?ie=UTF8&amp;qid=1506802440&amp;sr=8-1-fkmr1&amp;keywords=efron+tibshirani">Computer Age Statistical Inference: Algorithms, Evidence, and Data Science</a> (2016) chapter 9: <em>Survival Analysis and the EM algorithm</em></p>
</div>
</div>
<div id="markov-chain-monte-carlo" class="section level1">
<h1><span class="header-section-number">4</span> Markov Chain Monte Carlo</h1>
<div id="markov-chain-theory" class="section level2">
<h2><span class="header-section-number">4.1</span> Markov Chain theory</h2>
<p>Estimation can become complicated in higher dimensions. Given a high-dimensional probability density, we may not be able to visualize a proposal distribution that matches it well enough to draw i.i.d samples from and hope they coincide with the target density. Instead, we can use dependent sampling, where our next sample draw is intended to visit some area of high probability in the density, based off our knowledge of the previous draw. Sampling in this way gives a Markov Chain. However, we can no longer rely on the law of large numbers for convergence, but instead we have ergodic theorems which give similar asymptotic results for Markov Chains. To be ergodic, the MC must have certain nice properties:</p>
<p>-Every state must be accessible by the Markov Chain. Suppose we have a discrete Markov chain <span class="math inline">\(X = (X_0, X_1, \dots )\)</span> that has state space <span class="math inline">\(S = \{1, \dots, m\}\)</span>. We want that starting from any state, we have a non-zero probability of eventually reaching any other state. That is, the transition probability <span class="math inline">\(P_{ij} = P(X_{n+1} = j|X_n = i) &gt; 0\)</span> For some time step <span class="math inline">\(n\)</span>. This means the MC has a “regular” <span class="math inline">\(m\times m\)</span> transition matrix <strong>P</strong>, so for some power <span class="math inline">\(\textbf{P}^n\)</span>, the entry <span class="math inline">\(P_{ij}\)</span> will be positive. -Each state must also be recurrent: once the markov chain visits that state, the chain it “regenerates”&quot; itself and has a probability of visiting it some time in the future again. Thus the chain will visit that state infinitely many times; however, the proportion of visits will be different for each sate. -Additionally the chain must be aperiodic, which means it cannot get stuck in an infinite loop of visiting certain states back and forth.</p>
<p>If we draw a sample from this ergodic chain, it will reach a unique limiting stationary distribution <span class="math inline">\(\pi = (\pi_1,\dots, \pi_m)\)</span> which describes the on-average chance of being in one state at any given time-step. Since this distribution stays the same over time, we get convergence of the Markov Chain- a histogram of the chain at sample size <span class="math inline">\(n = 10^5\)</span> should match the histogram at <span class="math inline">\(n = 10^7\)</span>, which will reflect the proportion of times the markov chain visits each state as given by the limiting distribution. Using a sample from an ergodic MC is fundamentally identical to an i.i.d sample, so the ergodic theorem gives us the same result as the law of large numbers: <span class="math inline">\(\frac{1}{N}\sum_{i=1}^Nh(X_i) \approx E_f[h(X)]\)</span> where <span class="math inline">\(f\)</span> is the limiting distribution.</p>
<p>We can also use a continuous-state markov chain with an uncountable state space <span class="math inline">\(\chi\)</span> and a conditional distribution called the transition kernel <span class="math inline">\(\mathcal{K(x,y)}\)</span> which gives the probability of transitioning from state <span class="math inline">\(x\)</span> to state <span class="math inline">\(y\)</span>, defined on <span class="math inline">\(\chi \times \chi\)</span> with the property that <span class="math inline">\(\mathcal{K}(x,\centerdot) &gt;0\)</span> on its support (i.e all the states are accessible). A Monte Carlo method for simulating a distribution <span class="math inline">\(f\)</span> is to sample from an ergodic markov chain whose transition kernel converges to <span class="math inline">\(f\)</span>. The result is a sample <span class="math inline">\(X_1, \dots, X_N\)</span> approximately distributed from <span class="math inline">\(f\)</span> without having to directly simulate from <span class="math inline">\(f\)</span> itself!</p>
<p>See:<br />
Dobrow: <a href="https://www.amazon.com/Introduction-Stochastic-Processes-Robert-Dobrow-ebook/dp/B01DNVSQLW/ref=sr_1_1?s=digital-text&amp;ie=UTF8&amp;qid=1506824267&amp;sr=1-1&amp;keywords=Introduction+to+Stochastic+Processes+with+R">Introduction to Stochastic Processes with R</a> (2016) Chapter 3: <em>Markov Chains for the Long Term</em><br />
Robert, Casella: <a href="https://www.amazon.com/Monte-Statistical-Methods-Springer-Statistics/dp/0387212396/ref=sr_1_fkmr0_1?s=digital-text&amp;ie=UTF8&amp;qid=1506824633&amp;sr=8-1-fkmr0&amp;keywords=Monte+Carlo+Statistical+Methods+2004">Monte Carlo Statistical Methods</a> (2004) Chapter 7.1: <em>The MCMC Principle</em></p>
</div>
<div id="simulating-a-random-walk" class="section level2">
<h2><span class="header-section-number">4.2</span> Simulating a Random Walk</h2>
<p>A <em>simple random walk</em> is a markov chain <span class="math display">\[X^{(t+1)} |X^{(0)},\dots, X^{(t)} \sim \mathcal{K}(X^{(t)},X^{(t+1)})\]</span> that satisfies <span class="math inline">\(X^{(t+1)} = X^{(t)} + \epsilon_t\)</span>, where <span class="math inline">\(\epsilon_t\)</span> is independent gaussian noise <span class="math inline">\(\epsilon_t\sim\mathcal{N}(0,1)\)</span>. Then the transition kernel <span class="math inline">\(\mathcal(K) \sim \mathcal{N}(X^{(t)},1)\)</span></p>
<p>It turns out, the simple random walk does not converge, so it cannot be described by a stationary distribution.</p>
<pre class="r"><code>t &lt;- 10^5
rho &lt;- 1
markov_chain &lt;- numeric(t)
markov_chain[1] = rnorm(1)
for(i in 2:t){
  markov_chain[i] &lt;- rnorm(n = 1, mean = markov_chain[i-1] * rho, sd = 1 )
}



mc_frame &lt;- data.frame(head = markov_chain[1:(10^5/2)],
                       tail = markov_chain[(10^5/2+1):10^5])

ggplot(data = mc_frame) +
  geom_freqpoly(aes(x = head), col = &quot;blue&quot;,  alpha = .5) + 
  geom_freqpoly(aes(x = tail), col = &quot;orange&quot;, alpha = .5) </code></pre>
<p><img src="simulations_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>Since the head and tail of the random walk have completely different distributions, we can see that it won’t converge.</p>
<p>However, if we make a slight contraction, the random walk does in fact converge.</p>
<p>Consider the Markov Chain defined by <span class="math inline">\(X^{(t+1)} = \rho X^{(t)} + \epsilon_t\)</span> where <span class="math inline">\(\epsilon_t\sim\mathcal{N}(0,1)\)</span> Using <span class="math inline">\(\rho = .9\)</span>, we will show that the stationary distribution is <span class="math inline">\(\mathcal{N}\left(0, \frac{1}{1-\rho^2}\right)\)</span>.</p>
<pre class="r"><code>t &lt;- 10^5
rho &lt;- .9
markov_chain &lt;- numeric(t)
markov_chain[1] = rnorm(1)
for(i in 2:t){
  markov_chain[i] &lt;- rnorm(n = 1, mean = markov_chain[i-1] * rho, sd = 1 )
}

stationary_distribution &lt;-  rnorm(n = t, mean = 0, sd = sqrt(1/(1-rho^2)))

mc_frame &lt;- data.frame(mc = markov_chain,
                       s_dis = stationary_distribution)

ggplot(data = mc_frame) +
  geom_freqpoly(aes(x = mc), col = &quot;blue&quot;,  alpha = .5) + 
  geom_freqpoly(aes(x = s_dis), col = &quot;orange&quot;, alpha = .5) </code></pre>
<p><img src="simulations_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>Notice the the stationary distribution would not exist for the simple random walk: it is undefined for <span class="math inline">\(\rho = 1\)</span>.</p>
<p>See:</p>
<p>Robert, Casella: <a href="https://www.amazon.com/Introducing-Monte-Carlo-Methods-Use/dp/1441915753/ref=sr_1_1?ie=UTF8&amp;qid=1507053415&amp;sr=8-1&amp;keywords=Introducing+Monte+Carlo+Methods+with+R">Introducing Monte Carlo Methods with R</a> (2010) Chapter 6.2: <em>A Peek at Markov Chain Theory</em></p>
</div>
<div id="random-walk-sampler" class="section level2">
<h2><span class="header-section-number">4.3</span> Random Walk Sampler</h2>
<p>Here we use a random walk to generate a sample from a bivariate normal distribution. Though we already have ways to generate random multivaraite normals, this algorithm can be applied to sample from any exponential kernel.</p>
<p>We use a bivariate normal with mean 0 and standard deviation 3 multiplied by 2 to simulate the noise of the random walk. Increasing the noise of the walk can help explore the distribution faster, but may lead to more rejected proposals, slowing down convergence.</p>
<pre class="r"><code>library(mvtnorm)

N &lt;- 10^5

chain &lt;- matrix(rep(0,N*2), nrow = N)

#initialize X_0
chain[1,] &lt;- c(2,2)

#acceptance function
f &lt;- function(x){ dmvnorm(x)}


acceptance &lt;- function(y, x){
  min(f(y)/f(x) , 1)
}

#generates candidate move
biv_rnorm &lt;- function(){
  rnorm(n = 2, sd = 3)
}

#sample the chain
for(t in 1:(N-1)){

X_t &lt;- chain[t,]

Y &lt;- X_t + 2 * biv_rnorm()

alpha &lt;- acceptance(Y, X_t)

u &lt;- runif(n = 1)


if(u &lt; alpha){
  chain[t+1,] &lt;- Y
}
else{
  chain[t+1,] &lt;- X_t
}


}

hist(chain[,1])</code></pre>
<p><img src="simulations_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<pre class="r"><code>hist(chain[,2])</code></pre>
<p><img src="simulations_files/figure-html/unnamed-chunk-22-2.png" width="672" /></p>
<p>The histograms show the marginal distributions are standard normal, as expected.</p>
</div>
<div id="metropolis-hastings" class="section level2">
<h2><span class="header-section-number">4.4</span> Metropolis Hastings</h2>
<p>The original Metropolis Hastings algorithm was used to determine the ideal configuration of of a system of N particles. Let’s say each particle has a location in 2-dimensional space describes by <span class="math inline">\(r\)</span> and <span class="math inline">\(s\)</span> coordinates, and the state of the system is the coordinates of each particle at a given moment in time. A markov chain can describe the evolution of the system as it transitions from one particle configuration to the next. Assuming the particles are constrained in a unit square, a state vector would look like <span class="math inline">\(X = \{(r_1, s_1),\dots, (r_N,s_N)\}\in ([0,1]^2)^N\)</span> distributed according the Boltzmann distribution <span class="math inline">\(\pi(x) = \frac{1}{z}e^{-\mathcal{E}(x)}\)</span> where <span class="math inline">\(\mathcal{E}\)</span> is an energy function of the state. Our goal is to sample from the Boltzmann distribution and find its expected value, so we can determine the ideal configuration of the system. However, <span class="math inline">\(z\)</span> may be intractible and we don’t have a sampling procedure. Faced with this problem, the physicists Metropolis and Hastings invented one. Here’s how it works: we start with a target distribution <span class="math inline">\(\pi\)</span> we want to sample from, and construct a transition kernel that converges to <span class="math inline">\(\pi\)</span>. We need a symmetric proposal transition matrix <span class="math inline">\(Q\)</span> that suggests the next state of the Markov Chain based off the previous state. <span class="math inline">\(Q\)</span> can be as simple as a uniform distribution that chooses a nearby configuration at random, as long as it gives an equal transition probability of reversing that configuration. The actual transition matrix of the Markov Chain <span class="math inline">\(X\)</span> that we construct is given by <span class="math inline">\(T\)</span> and has transition probability <span class="math inline">\(T(X_{n+1}|X_n) =\)</span> (Probability that Q proposes transition to <span class="math inline">\(X_{n+1}=x^*\)</span>)(Probability that the transition to <span class="math inline">\(x^*\)</span> is accepted) and define P(accept <span class="math inline">\(x^{*}|X_n\)</span>) = min<span class="math inline">\(\{1, \frac{\pi(x^*)}{\pi(x)}\}\)</span>. If Q is symmetric, then <span class="math inline">\(X\)</span> is time reversible and therefore ergodic with limiting distribution <span class="math inline">\(\pi\)</span>. Let’s illustrate that <span class="math inline">\(\pi\)</span> is in fact the limiting distribution of T. Recall that a time-reversible Markov Chain is such that its stationary distribution satisfies the property of detailed balance: <span class="math inline">\(\pi_aT(a|b)=\pi_bT(b|a)\)</span>. In our example the proof hinges on the fact that we choose a symmetric proposal matrix Q. <span class="math display">\[\pi_bT(a|b) \\ =\pi_bQ(a|b)\min\{1, \frac{\pi_a}{\pi_b}\}\\ 
= Q(a|b)\min\{\pi_b, \pi_a\} \\
= Q(b|a)\min\{\pi_b, \pi_a\} \\ = \pi_aQ(b|a)\min\{\frac{\pi_b}{\pi_a}, 1\} \\ = \pi_aT(b|a)\]</span> Since <span class="math inline">\(T\)</span> is time reversible, <span class="math inline">\(\pi\)</span> is the unique limiting distribution of <span class="math inline">\(T\)</span>. This is the basis of the independence sampler algorithm.</p>
<p>See:<br />
<a href="https://www.youtube.com/watch?v=0j-Pq1OU4LY">Mathematical Monk on MCMC</a></p>
<p>Robert, Casella <a href="https://www.amazon.com/Introducing-Monte-Carlo-Methods-Use/dp/1441915753/ref=sr_1_1?ie=UTF8&amp;qid=1507053415&amp;sr=8-1&amp;keywords=Introducing+Monte+Carlo+Methods+with+R">Introducing Monte Carlo Methods with R</a> (2010) Chapter 6: <em>Metropolis-Hastings Algorithm</em></p>
</div>
<div id="comparison-with-accept-reject" class="section level2">
<h2><span class="header-section-number">4.5</span> Comparison with Accept-Reject</h2>
<p>Here is a comparison of simulations for a gamma(4.3,6.2) density using the following methods:</p>
<p>-<strong>a</strong>: accept-reject using a gamma(4,7) candidate</p>
<p>-<strong>b</strong>: Metropolis-Hastings using a gamma(4,7) candidate</p>
<p>-<strong>c</strong>: Metropolis-Hastings using a gamma(5,6) candidate</p>
<pre class="r"><code>g47=rgamma(5000,4,7)
u=runif(5000,max=dgamma(g47,4,7))
x=g47[u&lt;dgamma(g47,4.3,6.2)]
par(mfrow=c(1,3),mar=c(4,4,1,1))
hist(x,freq=FALSE,xlab=&quot;&quot;,ylab=&quot;&quot;,col=&quot;wheat2&quot;,
main=&quot;a: Accept-Rej with Ga(4.7) prop&quot;)
curve(dgamma(x,4.3,6.2),lwd=2,col=&quot;sienna&quot;,add=T)

a &lt;- length(x)/5000

X=rep(0,5000)
X[1]=rgamma(1,4.3,6.2)
for (t in 2:5000){
rho=(dgamma(X[t-1],4,7)*dgamma(g47[t],4.3,6.2))/
(dgamma(g47[t],4,7)*dgamma(X[t-1],4.3,6.2))
X[t]=X[t-1]+(g47[t]-X[t-1])*(runif(1)&lt;rho) #move to g47[t] if it is accepted, otherwise stay
}
hist(X,freq=FALSE,xlab=&quot;&quot;,ylab=&quot;&quot;,col=&quot;wheat2&quot;,
main=&quot;b: Met-Hast with Ga(4,7) prop&quot;)
curve(dgamma(x,4.3,6.2),lwd=2,col=&quot;sienna&quot;,add=T)

b &lt;- length(unique(X))/5000

g56=rgamma(5000,5,6)
X[1]=rgamma(1,4.3,6.2)
for (t in 2:5000){
rho=(dgamma(X[t-1],5,6)*dgamma(g56[t],4.3,6.2))/
(dgamma(g56[t],5,6)*dgamma(X[t-1],4.3,6.2))
X[t]=X[t-1]+(g56[t]-X[t-1])*(runif(1)&lt;rho)
}
c &lt;- length(unique(X))/5000
hist(X,freq=FALSE,xlab=&quot;&quot;,ylab=&quot;&quot;,col=&quot;wheat2&quot;,
main=&quot;c: Met-Hast with Ga(5,6) prop&quot;)
curve(dgamma(x,4.3,6.2),lwd=2,col=&quot;sienna&quot;,add=T)</code></pre>
<p><img src="simulations_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<table>
<thead>
<tr class="header">
<th>Method</th>
<th>Efficiency</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>a</td>
<td>0.8432</td>
</tr>
<tr class="even">
<td>b</td>
<td>0.7934</td>
</tr>
<tr class="odd">
<td>c</td>
<td>0.781</td>
</tr>
</tbody>
</table>
<p>The three methods produce similar results.</p>
<p>Robert, Casella <a href="https://www.amazon.com/Introducing-Monte-Carlo-Methods-Use/dp/1441915753/ref=sr_1_1?ie=UTF8&amp;qid=1507053415&amp;sr=8-1&amp;keywords=Introducing+Monte+Carlo+Methods+with+R">Introducing Monte Carlo Methods with R</a> (2010) Chapter 6: <em>Metropolis-Hastings Algorithm</em>, <strong>exercise 6.9</strong></p>
</div>
<div id="multi-stage-gibbs-sampler" class="section level2">
<h2><span class="header-section-number">4.6</span> Multi-stage Gibb’s sampler</h2>
<p>The Gibb’s sampler is a method to sample from a multivariate distrubtion by generating a Markov Chain. Suppose we have <span class="math inline">\(m\)</span>-dimensional random variable <span class="math inline">\(X = (X_1,\dots,X_m) \sim \pi\)</span>. The Gibb’s sampler samples from the <em>full conditionals</em> of <span class="math inline">\(\pi\)</span>: <span class="math inline">\(\pi(X_1|X_2, \dots X_m)\)</span>, <span class="math inline">\(\pi(X_2|X_1, X_3, \dots, X_m)\)</span>, <span class="math inline">\(\dots\)</span>, <span class="math inline">\(\pi(X_m|X_1,\dots ,X_{m-1})\)</span> to generate a Markov Chain whose target distribution is <span class="math inline">\(\pi(X)\)</span>. It turns out the Gibb’s Sampler is a special case of Metropolis-Hastings where the probability of accepting the proposed state is always 1. The proposed state is determined iteratively sing the full conditional distributions. If we initialize the first state as <span class="math inline">\((x^{(0)}_1,\dots, x^{(0)}_m\)</span>), we have <span class="math inline">\(x^{(1)}_1\sim P(X_1|x^{(0)}_2, \dots, x^{(0)}_m)\)</span>. Then update the current state with <span class="math inline">\(x_1^{(0)} \rightarrow x_1^{(1)}\)</span> and sample the next dimension <span class="math inline">\(x^{(1)}_2\sim P(X_2|x_1^{(1)}, x^{(0)}_3, \dots, x^{(0)}_m)\)</span>. Keep in mind that the superscript is the time-step and the subscript is the dimension. We iterate <span class="math inline">\(m\)</span> times to generate the proposal for the next state, which is then accepted automatically, and repeat to get a sample. The sample we generate is a Markov Chain with limiting distribution <span class="math inline">\(\pi\)</span>, which is the target distribution. The advantage of the Gibb’s sampler is that it can sample from a high-dimensional density using univariate densities, simplifying the problem. Of course, we will need to be able to determine the conditional distributions before we can sample from them.</p>
<p>We will implement the Gibb’s sampler to simulate the following density: <span class="math display">\[\pi(x, p, n) \propto \binom{n}{x} p^x(1-p)^{n-x}\frac{4^n}{n!}\]</span> where <span class="math inline">\(x, n \in \mathbb{Z}_{\geq0}\)</span> and <span class="math inline">\(p\in (0,1)\)</span> To identify the conditional distributions, hold the two other variable constant, and we see that<span class="math display">\[X| N=n, P=p \propto \text{binomial}(n, p)\]</span> <span class="math display">\[P|X = x, N= n \propto \text{beta}(x+1, n-x+1)\]</span> <span class="math display">\[N|P=p, X=x \propto Z + x \text{ where } Z\sim \text{poisson}(\lambda = 4(1-p))\]</span></p>
<pre class="r"><code>N &lt;- 10^3
sim &lt;- matrix(rep(0,3*N),ncol=3)

#Initialize first state
sim[1, ] &lt;- c(1,.5,2) #x, p, n

#Run Gibb&#39;s Sampler
for(i in 2:N){
  sim[i,1] &lt;- rbinom(1,sim[i-1,3],sim[i-1,2])
  sim[i,2] &lt;- rbeta(1,sim[i,1]+1,sim[i-1,3]-sim[i,1]+1)
  sim[i,3] &lt;- rpois(1,4*(1-sim[i,2]))+sim[i,1] 
}

#plot marginal distributions
gibbs_sample &lt;- data.frame(x = sim[, 1],
                           p = sim[, 2],
                           n = sim[, 3])


marginals &lt;- list(NULL, NULL, NULL)

chart &lt;- function(var){
  ggplot(data = gibbs_sample, aes_(x = var)) + geom_histogram(color = &quot;violet&quot;)
}

#note: the input to chart is a name, not a string
for(i in 1:3){
  marginals[[i]] &lt;-  chart(as.name(names(gibbs_sample)[i]))
}

grid.arrange(marginals[[1]], marginals[[2]], marginals[[3]], ncol = 3, top = &quot;Marginal Distributions&quot;)</code></pre>
<p><img src="simulations_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>See:<br />
Dobrow: <a href="https://www.amazon.com/Introduction-Stochastic-Processes-Robert-Dobrow-ebook/dp/B01DNVSQLW/ref=sr_1_1?s=digital-text&amp;ie=UTF8&amp;qid=1506824267&amp;sr=1-1&amp;keywords=Introduction+to+Stochastic+Processes+with+R">Introduction to Stochastic Processes with R</a> (2016) <em>chapter 5.3</em>: <strong>gibb’s sampler</strong></p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
