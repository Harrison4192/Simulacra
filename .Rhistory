sum.FWD <- summary(FWD.mod)
show_metrics(sum.FWD)
FWD.mod <- regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward")
sum.FWD <- summary(FWD.mod)
show_metrics(sum.FWD)
microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward"))
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(ISLR)
library(tidyverse)
library(glmnet)
library(magrittr)
library(microbenchmark)
FWD.mod <- regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward")
sum.FWD <- summary(FWD.mod)
show_metrics(sum.FWD)
microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward"))$mean
microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward")) %>% names()
microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward")) %>% str()
microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward"))$expr %>% str()
microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward"))
microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17))
BEST_time <- microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward"))
FWD_time <- microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17))
BEST_time
FWD_time
FWD_time <- microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward"))
BEST_time <- microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17))
BEST_time
FWD_time
FWD.mod <- regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward")
sum.FWD <- summary(FWD.mod)
sum.FWD
show_metrics(sum.FWD)
sum.FWD$which
sum.FWD$which[[10, ]]
sum.FWD$which[10, ]
data_df
data_df
College
X = model.matrix(Apps ~ . -1, data = College)
Y = College$Apps
data_df <- cbind(as.data.frame(X), College[, "Apps"]) %>% rename(Apps = `College[, "Apps"]`)
X
X = model.matrix(Apps ~ . +0, data = College)
Y = College$Apps
data_df <- cbind(as.data.frame(X), College[, "Apps"]) %>% rename(Apps = `College[, "Apps"]`)
X
X = model.matrix(~ Apps -1, data = College)
Y = College$Apps
data_df <- cbind(as.data.frame(X), College[, "Apps"]) %>% rename(Apps = `College[, "Apps"]`)
X
X = model.matrix(Apps ~ . +0, data = College)
Y = model.matrix(~ Apps + 0, data = College)
data_df <- cbind(as.data.frame(X), as.data.frame(Y))
X
data_df
X = model.frame(Apps ~ . +0, data = College)
Y = model.frame(~ Apps + 0, data = College)
data_df <- cbind(X, Y)
X = model.frame(Apps ~ . +0, data = College) %>% select(-PrivateNo)
X %>% names
data_df
X
data_df
X = model.frame(Apps ~ . +0, data = College)
Y = model.frame(~ Apps + 0, data = College)
data_df <- cbind(X, Y)
X
data_df
X = model.frame(Apps ~ . - 1, data = College)
Y = model.frame(~ Apps + 0, data = College)
data_df <- cbind(X, Y)
X
data_df
X = model.matrix(Apps ~ . - 1, data = College)
Y = model.frame(~ Apps + 0, data = College)
data_df <- cbind(X, Y)
X
data_df
X = model.frame(Apps ~ . - 1, data = College)
Y = model.frame(~ Apps + 0, data = College)
data_df <- cbind(X, Y)
X
data_df
X = model.matrix(Apps ~ . - 1, data = College)
Y = model.matrix(Apps + 0, data = College)
X = model.matrix(Apps ~ . - 1, data = College)
Y = model.matrix(Apps ~ . + 0, data = College)
data_df <- as.data.frame(cbind(X, Y))
X
data_df
X = model.matrix.lm(Apps ~ . - 1, data = College)
Y = model.matrix(Apps ~ . + 0, data = College)
data_df <- as.data.frame(cbind(X, Y))
data_df
X = model.matrix.default(Apps ~ . - 1, data = College)
Y = model.matrix(Apps ~ . + 0, data = College)
data_df <- as.data.frame(cbind(X, Y))
data_df
X = model.matrix(Apps ~ . - 1, data = College)
Y = model.matrix(Apps ~ . + 0, data = College)
data_df <- as.data.frame(cbind(X, Y))
data_df
X
Y
X = model.matrix(Apps ~ . - 1, data = College)
Y = model.matrix(Apps ~ . + 0, data = College)
data_df <- as.data.frame(cbind(X, Y))
X
Y
X = model.matrix(Apps ~ . - 1, data = College)
Y = model.matrix(~ Apps + 0, data = College)
data_df <- as.data.frame(cbind(X, Y))
Y
X = model.matrix(Apps ~ . - 1, data = College)[, -1]
Y = model.matrix(~ Apps + 0, data = College)
data_df <- as.data.frame(cbind(X, Y))
data_df
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(ISLR)
library(tidyverse)
library(glmnet)
library(magrittr)
library(microbenchmark)
str(College)
X = model.matrix(Apps ~ . - 1, data = College)[, -1]
Y = model.matrix(~ Apps + 0, data = College)
data_df <- as.data.frame(cbind(X, Y))
train <- sample(1:nrow(X), replace = FALSE, round(nrow(X) * .25))
X.train <- X[train, ]
Y.train <- Y[train]
X.test <- X[-train, ]
Y.test <- Y[-train]
OLS.mod <- glmnet(X.train, Y.train)
OLS.pred <- predict(OLS.mod, newx = X.test)
RMSE <- function(x){sqrt(sum((x-Y.test)^2))/length(x)}
Percent.Error <- function(x){RMSE(x)/mean(Y) * 100}
OLS.RMSE <- RMSE(OLS.pred)
OLS.Percent.Err <- Percent.Error(OLS.pred)
results <- tibble(model = "OLS",
RMSE = OLS.RMSE,
)
knitr::kable(results, digits = 3)
grid <- 10^ seq (10,-2, length =100)
ridge.mod <- glmnet(X.test, Y.test, alpha = 0, lambda = grid)
# alpha = 0 specifies that we are using a Ridge Regression.
# glmnet automatically does centering first; Standardize = TRUE by default
dim(coef(ridge.mod))
el2norm <- function(x){sqrt(sum(x^2))}
el2norm.r <- function(col){el2norm(coef(ridge.mod)[, col])}
coef(ridge.mod)[,c(10,50,90)] %>% rbind( map_dbl(c(10,50,90), el2norm.r) ) %>% rbind(ridge.mod$lambda[c(10,50,90)])
predict(ridge.mod, s=80, type="coefficients")
# print(ridge.mod)   output is too long
set.seed(10)
ridge.cv <- cv.glmnet(X.train, Y.train, alpha = 0)
ridge.pred <- predict(ridge.cv, s="lambda.min", newx = X.test)
ridge.RMSE <- RMSE(ridge.pred)
bestlam <- ridge.cv$lambda.min
set.seed(1)
lasso.cv <- cv.glmnet(X.train, Y.train, alpha = 1)
lasso.lam <- lasso.cv$lambda.min
coef(lasso.cv, s = "lambda.min")
lasso.mod <- glmnet(X.train, Y.train, alpha = 1, lambda = grid)
lasso.pred <- predict(lasso.mod, s=lasso.lam, newx = X.test)
lasso.RMSE <- RMSE(lasso.pred)
results <- rbind(results, list("Ridge", ridge.RMSE), list("Lasso", lasso.RMSE))
knitr::kable(results, digits = 3)
library(pls)
set.seed(2)
PCR.mod <- pcr(Apps ~ ., subset = train, data = data_df,  validation = "CV")
validationplot(PCR.mod, val.type = "MSEP")
summary(PCR.mod)
PCR.pred <- predict(PCR.mod, X.test, ncomp = 3)
PCR.RMSE <- RMSE(PCR.pred)
results <- rbind(results,  list("PCR", PCR.RMSE))
knitr::kable(results, digits = 3)
PLS.mod <- plsr(Apps ~ ., data = data_df, subset = train, validation = "CV")
summary(PLS.mod)
validationplot(PLS.mod)
PLS.pred <- predict(PLS.mod, X.test, ncomp = 3)
PLS.RMSE <- RMSE(PLS.pred)
results <- rbind(results, list("PLS", PLS.RMSE))
knitr::kable(results, digits = 3)
library(caret)
caret_RMSE <- function(x){sqrt(sum((x-Y.test)^2))/length(x)}
trainControl <- trainControl(method="cv", number=5)
my_caret <- function(method_name){
#this function accepts the name of the method and returns its RMSE from testing it on our specified College dataset
method_fit <- train(Apps~., data=data_df, method=method_name, metric="RMSE", preProc=c("center","scale"), trControl=trainControl)
method_predictions <- predict(method_fit, X.test)
method_RMSE <- caret_RMSE(method_predictions)
list(method_name, method_RMSE)
}
caret_names <- list("lm", "lasso", "ridge", "glmnet", "pcr", "pls", "lars")
map(caret_names, my_caret) %>%
transpose() %>%
map(unlist) %>%
set_names(c("models","RMSE")) %>%
as_tibble() %>%
arrange(RMSE)->
caret_table
knitr::kable(caret_table, digits = 3, booktabs = TRUE, caption = "Result produced by Caret. Models arranged by RMSE.")
library(leaps)
BEST.mod_9 = regsubsets(Apps ~ ., data_df)
summary(BEST.mod_9)
BEST.mod_17 <- regsubsets(Apps ~ ., data_df, nvmax = 17)
bmod.summary <- summary(BEST.mod_17)
show_metrics <- function(my_summary){
metrics <- c("adjr2", "rsq", "bic", "cp")
best_df <- as.data.frame(`[`(my_summary, metrics))
best_df_melt <- best_df %>% gather(key = "metric", value = "value") %>% mutate(model = rep(1:17, 4))
(ggplot(data = best_df_melt, aes(x = model, y = value, color = metric)) +
geom_line() +
facet_grid(metric ~ ., scales = "free_y")) %>% print()
c(map_dbl(best_df[c("adjr2", "rsq")], which.max), map_dbl(best_df[c("bic", "cp")], which.min))
}
show_metrics(bmod.summary)
FWD.mod <- regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward")
sum.FWD <- summary(FWD.mod)
sum.FWD
show_metrics(sum.FWD)
FWD_time <- microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward"))
BEST_time <- microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17))
BEST_time
FWD_time
sum.FWD$which[10, ]
sum.FWD$which[10, ] == bmod.summary$which[10, ]
source('~/Desktop/projects/Github/Simulacra/build_site.R', echo=TRUE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(ISLR)
library(tidyverse)
library(glmnet)
library(magrittr)
library(microbenchmark)
str(College)
X = model.matrix(Apps ~ . - 1, data = College)[, -1]
Y = model.matrix(~ Apps + 0, data = College)
data_df <- as.data.frame(cbind(X, Y))
train <- sample(1:nrow(X), replace = FALSE, round(nrow(X) * .25))
X.train <- X[train, ]
Y.train <- Y[train]
X.test <- X[-train, ]
Y.test <- Y[-train]
OLS.mod <- glmnet(X.train, Y.train)
OLS.pred <- predict(OLS.mod, newx = X.test)
RMSE <- function(x){sqrt(sum((x-Y.test)^2))/length(x)}
Percent.Error <- function(x){RMSE(x)/mean(Y) * 100}
OLS.RMSE <- RMSE(OLS.pred)
OLS.Percent.Err <- Percent.Error(OLS.pred)
results <- tibble(model = "OLS",
RMSE = OLS.RMSE,
)
knitr::kable(results, digits = 3)
grid <- 10^ seq (10,-2, length =100)
ridge.mod <- glmnet(X.train, Y.train, alpha = 0, lambda = grid)
# alpha = 0 specifies that we are using a Ridge Regression.
# glmnet automatically does centering first; Standardize = TRUE by default
el2norm <- function(x){sqrt(sum(x^2))}
el2norm.r <- function(col){el2norm(coef(ridge.mod)[, col])}
coef(ridge.mod)[,c(10,50,90)] %>% rbind( map_dbl(c(10,50,90), el2norm.r) ) %>% rbind(ridge.mod$lambda[c(10,50,90)])
knitr::opts_chunk$set(cache = F)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(ISLR)
library(tidyverse)
library(glmnet)
library(magrittr)
library(microbenchmark)
knitr::opts_chunk$set(cache = F)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(ISLR)
library(tidyverse)
library(glmnet)
library(magrittr)
library(microbenchmark)
str(College)
X = model.matrix(Apps ~ . - 1, data = College)[, -1]
Y = model.matrix(~ Apps + 0, data = College)
data_df <- as.data.frame(cbind(X, Y))
train <- sample(1:nrow(X), replace = FALSE, round(nrow(X) * .25))
X.train <- X[train, ]
Y.train <- Y[train]
X.test <- X[-train, ]
Y.test <- Y[-train]
OLS.mod <- lm(Apps ~ . , data = data_df)
OLS.pred <- predict(OLS.mod, newx = X.test)
RMSE <- function(x){sqrt(sum((x-Y.test)^2))/length(x)}
Percent.Error <- function(x){RMSE(x)/mean(Y) * 100}
OLS.RMSE <- RMSE(OLS.pred)
OLS.Percent.Err <- Percent.Error(OLS.pred)
results <- tibble(model = "OLS",
RMSE = OLS.RMSE,
)
knitr::kable(results, digits = 3)
grid <- 10^ seq (10,-2, length =100)
ridge.mod <- glmnet(X.train, Y.train, alpha = 0, lambda = grid)
# alpha = 0 specifies that we are using a Ridge Regression.
# glmnet automatically does centering first; Standardize = TRUE by default
dim(coef(ridge.mod))
el2norm <- function(x){sqrt(sum(x^2))}
el2norm.r <- function(col){el2norm(coef(ridge.mod)[, col])}
coef(ridge.mod)[,c(10,50,90)] %>% rbind( map_dbl(c(10,50,90), el2norm.r) ) %>% rbind(ridge.mod$lambda[c(10,50,90)])
predict(ridge.mod, s=80, type="coefficients")
# print(ridge.mod)   output is too long
set.seed(10)
ridge.cv <- cv.glmnet(X.train, Y.train, alpha = 0)
ridge.pred <- predict(ridge.cv, s="lambda.min", newx = X.test)
ridge.RMSE <- RMSE(ridge.pred)
bestlam <- ridge.cv$lambda.min
set.seed(1)
lasso.cv <- cv.glmnet(X.train, Y.train, alpha = 1)
lasso.lam <- lasso.cv$lambda.min
coef(lasso.cv, s = "lambda.min")
lasso.mod <- glmnet(X.train, Y.train, alpha = 1, lambda = grid)
lasso.pred <- predict(lasso.mod, s=lasso.lam, newx = X.test)
lasso.RMSE <- RMSE(lasso.pred)
results <- rbind(results, list("Ridge", ridge.RMSE), list("Lasso", lasso.RMSE))
knitr::kable(results, digits = 3)
library(pls)
set.seed(2)
PCR.mod <- pcr(Apps ~ ., subset = train, data = data_df,  validation = "CV")
validationplot(PCR.mod, val.type = "MSEP")
summary(PCR.mod)
PCR.pred <- predict(PCR.mod, X.test, ncomp = 3)
PCR.RMSE <- RMSE(PCR.pred)
results <- rbind(results,  list("PCR", PCR.RMSE))
knitr::kable(results, digits = 3)
PLS.mod <- plsr(Apps ~ ., data = data_df, subset = train, validation = "CV")
summary(PLS.mod)
validationplot(PLS.mod)
PLS.pred <- predict(PLS.mod, X.test, ncomp = 3)
PLS.RMSE <- RMSE(PLS.pred)
results <- rbind(results, list("PLS", PLS.RMSE))
knitr::kable(results, digits = 3)
library(caret)
caret_RMSE <- function(x){sqrt(sum((x-Y.test)^2))/length(x)}
trainControl <- trainControl(method="cv", number=5)
my_caret <- function(method_name){
#this function accepts the name of the method and returns its RMSE from testing it on our specified College dataset
method_fit <- train(Apps~., data=data_df, method=method_name, metric="RMSE", preProc=c("center","scale"), trControl=trainControl)
method_predictions <- predict(method_fit, X.test)
method_RMSE <- caret_RMSE(method_predictions)
list(method_name, method_RMSE)
}
caret_names <- list("lm", "lasso", "ridge", "glmnet", "pcr", "pls", "lars")
map(caret_names, my_caret) %>%
transpose() %>%
map(unlist) %>%
set_names(c("models","RMSE")) %>%
as_tibble() %>%
arrange(RMSE)->
caret_table
knitr::kable(caret_table, digits = 3, booktabs = TRUE, caption = "Result produced by Caret. Models arranged by RMSE.")
library(leaps)
BEST.mod_9 = regsubsets(Apps ~ ., data_df)
summary(BEST.mod_9)
BEST.mod_17 <- regsubsets(Apps ~ ., data_df, nvmax = 17)
bmod.summary <- summary(BEST.mod_17)
show_metrics <- function(my_summary){
metrics <- c("adjr2", "rsq", "bic", "cp")
best_df <- as.data.frame(`[`(my_summary, metrics))
best_df_melt <- best_df %>% gather(key = "metric", value = "value") %>% mutate(model = rep(1:17, 4))
(ggplot(data = best_df_melt, aes(x = model, y = value, color = metric)) +
geom_line() +
facet_grid(metric ~ ., scales = "free_y")) %>% print()
c(map_dbl(best_df[c("adjr2", "rsq")], which.max), map_dbl(best_df[c("bic", "cp")], which.min))
}
show_metrics(bmod.summary)
FWD.mod <- regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward")
sum.FWD <- summary(FWD.mod)
show_metrics(sum.FWD)
FWD_time <- microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17, method = "forward"))
BEST_time <- microbenchmark(regsubsets(Apps ~ ., data = data_df, nvmax = 17))
BEST_time
FWD_time
sum.FWD$which[10, ] == bmod.summary$which[10, ]
knitr::opts_chunk$set(cache = Fx)
knitr::opts_chunk$set(cache = T)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
library(ISLR)
library(tidyverse)
library(glmnet)
library(magrittr)
library(microbenchmark)
str(data_df)
tree.College <- tree(PrivateYes ~ ., data = data_df)
library(tree)
install.packages('tree')
library(tree)
tree.College <- tree(PrivateYes ~ ., data = data_df)
summary(tree.College)
library(tree)
tree.College <- tree(PrivateYes ~ ., data = College)
library(tree)
tree.College <- tree(Private ~ ., data = College)
summary(tree.College)
plot(tree.College)
text(tree.College, pretty = 0)
plot(tree.College)
text(tree.College)
plot(tree.College)
text(tree.College, pretty = 10)
plot(tree.College)
text(tree.College)
plot(tree.College)
plot(tree.College)
text(tree.College)
College.test <- College[-train, ]
Private.test <- College$Private[-train]
tree.College <- tree(Private ~ ., data = College, subset = train)
tree.pred <- predict(tree.College, College.test, type = "class")
table(tree.pred, College.test)
College.test <- College[-train, ]
Private.test <- College$Private[-train]
tree.College <- tree(Private ~ ., data = College, subset = train)
tree.pred <- predict(tree.College, College.test, type = "class")
table(tree.pred, Private.test)
College.test <- College[-train, ]
Private.test <- College$Private[-train]
tree.College <- tree(Private ~ ., data = College, subset = train)
tree.pred <- predict(tree.College, College.test, type = "class")
myTable <- table(tree.pred, Private.test)
summary(myTable)
typeof(myTable)
myTable[1,2] + myTable[2, 1]
(myTable[1,2] + myTable[2, 1]) / (myTable[1, 1] + myTable[2, 2])
(myTable[1,2] + myTable[2, 1]) / (sum(myTable))
myTable
sum(myTable)
cv.college = cv.tree(tree.College, FUN = prune.misclass)
cv.college
as.data.frame(cv.college)
as.data.frame(cv.college[c('size', 'dev', 'k')])
cv_df <- as.data.frame(cv.college[c('size', 'dev', 'k')]) %>% gather(key = "metric", value = "value")
ggplot(data = cv_df, aes(col = metric)) +
geom_line()
cv_df <- as.data.frame(cv.college[c('size', 'dev', 'k')]) %>% gather(key = "metric", value = "value")
# ggplot(data = cv_df, aes(col = metric)) +
#   geom_line()
cv_df <- as.data.frame(cv.college[c('size', 'dev', 'k')]) %>% gather(key = "metric", value = "value")
# ggplot(data = cv_df, aes(col = metric)) +
#   geom_line()
cv_df
cv_df <- as.data.frame(cv.college[c('size', 'dev', 'k')]) %>% gather(key = "metric", value = "value")
ggplot(data = cv_df, aes(x = metric, col = metric)) +
geom_line()
cv_df <- as.data.frame(cv.college[c('size', 'dev', 'k')]) %>% gather(key = "metric", value = "value")
ggplot(data = cv_df, aes(x = metric, y = 1, col = metric)) +
geom_line()
cv_df <- as.data.frame(cv.college[c('size', 'dev', 'k')]) %>% gather(key = "metric", value = "value")
ggplot(data = cv_df, aes(x = 1, y = metric, col = metric)) +
geom_line()
cv_df <- as.data.frame(cv.college[c('size', 'dev', 'k')]) %>% gather(key = "metric", value = "value")
ggplot(data = cv_df, aes(x = metric, y = value, col = metric)) +
geom_line()
cv_df <- as.data.frame(cv.college[c('size', 'dev', 'k')]) %>% gather(key = "metric", value = "value")
ggplot(data = cv_df, aes(x = value, y = value, col = metric)) +
geom_line()
cv_df <- as.data.frame(cv.college[c('size', 'dev', 'k')]) %>% gather(key = "metric", value = "value")
ggplot(data = cv_df, aes(x = value,  col = metric)) +
geom_line()
cv_df <- as.data.frame(cv.college[c('size', 'dev', 'k')]) %>% gather(key = "metric", value = "value") %>% mutate(index = rep(1:length(cv.college$size), 3))
ggplot(data = cv_df, aes(x = index, y = value col = metric)) +
cv_df <- as.data.frame(cv.college[c('size', 'dev', 'k')]) %>% gather(key = "metric", value = "value") %>% mutate(index = rep(1:length(cv.college$size), 3))
ggplot(data = cv_df, aes(x = index, y = value, col = metric)) +
geom_line()
prune.college <- prune.misclass(tree.college, best = 3)
College.test <- College[-train, ]
Private.test <- College$Private[-train]
tree.college <- tree(Private ~ ., data = College, subset = train)
tree.pred <- predict(tree.college, College.test, type = "class")
myTable <- table(tree.pred, Private.test)
cv.college = cv.tree(tree.college, FUN = prune.misclass)
cv.college
cv_df <- as.data.frame(cv.college[c('size', 'dev', 'k')]) %>% gather(key = "metric", value = "value") %>% mutate(index = rep(1:length(cv.college$size), 3))
ggplot(data = cv_df, aes(x = index, y = value, col = metric)) +
geom_line()
prune.college <- prune.misclass(tree.college, best = 3)
plot(prune.college)
text(prune.college, pretty = 0)
prune.pred = predict(prune.college, College.test, type = "class")
table(prune.pred, Private.test)
College.test <- College[-train, ]
Private.test <- College$Private[-train]
tree.college <- tree(Private ~ ., data = College, subset = train)
tree.pred <- predict(tree.college, College.test, type = "class")
tree.table <- table(tree.pred, Private.test)
error_rate = function(myTable)  {(myTable[1,2] + myTable[2, 1]) / (sum(myTable))}
error_rate(tree.table)
prune.pred = predict(prune.college, College.test, type = "class")
prune.table <- table(prune.pred, Private.test)
prune.table
error_rate(prune.table)
prune.college <- prune.misclass(tree.college, best = 4)
plot(prune.college)
text(prune.college, pretty = 0)
prune.pred = predict(prune.college, College.test, type = "class")
prune.table <- table(prune.pred, Private.test)
prune.table
error_rate(prune.table)
error_rate = function(myTable)  {(myTable[1,2] + myTable[2, 1]) / (sum(myTable))}
error_rate(tree.table)
prune.table
error_rate(prune.table)
